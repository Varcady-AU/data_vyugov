{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание проекта\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "### Постановка задачи\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "### Описание данных\n",
    "Данные находятся в файле `toxic_comments.csv`. \n",
    "Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1. Подготовка](#1-bullet)\n",
    "### [2. Обучение](#2-bullet)\n",
    "### [3. Выводы](#3-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import re, string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка <a id='1-bullet'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/vyugo/Documents/!Python/2. Проекты Я.Практикум/12. Модель классификации текста на положительный и отрицательный/Рабочие файлы/toxic_comments.csv')\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверим баланс классов\n",
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим наши данные на признаки и целевой признак\n",
    "features = df.drop(['toxic'], axis = 1)\n",
    "target = df['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим 50% значений с 0 целевым признаком, так как их слишком много по отношению к 1 \n",
    "from sklearn.utils import shuffle # импортируем функцию перемешивания сообщений\n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0].sample(frac=fraction, random_state=12345)\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0].sample(frac=fraction, random_state=12345)\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones])\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_down, target_down = downsample(features, target, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87898, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_down.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобъем наши данные на тренировочную и тестовую выборки:  70/30%\n",
    "features_train, features_test, target_train, target_test = (\n",
    "                train_test_split(features_down, target_down, test_size=0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим модель английского языка en Spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "# Загрузим стопслова английского языка en\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токенизация текста\n",
    "def spacy_tokenize(text):\n",
    "    doc = nlp.tokenizer(text)\n",
    "    return [token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаление стопслов из текста\n",
    "def remove_stopwords(tokens):\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in spacy_stopwords:\n",
    "            cleaned_tokens.append(token)\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Лемматизация текста с предварительной токенизацией\n",
    "def spacy_lemmatize(text):\n",
    "    doc = nlp.tokenizer(text)\n",
    "    return [token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_lemm(text):\n",
    "    doc = nlp.tokenizer(text.lower()) # токенизируем текст, предварительно переведя в нижний регистр\n",
    "    lemm_text = [token.lemma_ for token in doc] # лемматизируем текст\n",
    "    \n",
    "    cleaned_tokens = []\n",
    "    for token in lemm_text: # Удалим стопслова из текста\n",
    "        if token not in spacy_stopwords:\n",
    "            cleaned_tokens.append(token)\n",
    "        \n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spacy_lemm(df['text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(df['text'][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция по обработке сообщений всего датасета\n",
    "def lemm_array(df):\n",
    "    array = []\n",
    "    for i in notebook.tqdm(range(df.shape[0])):\n",
    "        message = \" \".join(spacy_lemm(df.iloc[i])) # Соберем сообщение в один текст\n",
    "        message_re = re.sub(r'[^a-zA-Z]', ' ', message) # Удалим из сообщения посторонние символы и цифры\n",
    "        list_j = \" \".join(message_re.split()) # Удалим лишние пробелы\n",
    "        array.append(list_j) # Соберем все сообщения в единый список\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1f52cf48034340961a89661fba8036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['explanation edit username hardcore metallica fan revert vandalisms closure gas vote new york doll fac remove template talk page PRON retire now',\n",
       " 'd aww match background colour PRON seemingly stick thank talk january utc']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemm_array(df['text'][:2]) # Проверим качество проделанной работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\", \"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\"]\n"
     ]
    }
   ],
   "source": [
    "print(list(df['text'][:2])) # Для сравнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a68bf3e6d9e4975951a860593cfe84a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Корпус с тренировочной выборкой\n",
    "corpus_train = lemm_array(features_train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a654e9993b504ecf8e064bbc7ba4fcaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Корпус с тестовой выборкой\n",
    "corpus_test = lemm_array(features_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовим модель по обращению подготовленного текста в матрицу с удалением стопслов\n",
    "tf_idf = TfidfVectorizer().fit(corpus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тренировочная матрица\n",
    "features_tr = tf_idf.transform(corpus_train)\n",
    "# Тестовая матрица\n",
    "features_tt = tf_idf.transform(corpus_test)\n",
    "# Удалим неиспользуемые в дальнейшем данные\n",
    "del corpus_train\n",
    "del corpus_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61528,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(61528, 84269)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверим соответствие тренировочной матрицы признаков и целевого признака\n",
    "print(target_train.shape)\n",
    "features_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26370,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(26370, 84269)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверим соответствие тестовой матрицы признаков и целевого признака\n",
    "print(target_test.shape)\n",
    "features_tt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "1. Исходный файл состоит из 159571 сообщений с размеченой областью \"toxic\";\n",
    "2. Текст содержит много слэнговых выражений, цифр, символов и часто состоит не из одного предложения, что осложняет адекватный его перевод в цифровой вид пригодный для обучения модели;\n",
    "3. Мы изначально разделили данные на обучающую и тестовую выборки для удобства обработки;\n",
    "4. Подготовка текста переводу в матричный вид состоит из двух основных этапов. На первом этапе мы создали функцию lemmatize которая способна комплексно обработать одно сообщение: удалить регулярные выражения, пробелы и провести лемматизацию. На втором этапе мы создали функцию lemm_array с помошью которой по порядку скармливаем наши сообщения для комплексной обработки.\n",
    "5. Итог нашей подготовки 2 матрицы признаков - обучающая и тестовая."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение<a id='2-bullet'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Найдем лучшие гиперпараметры LogisticRegression с помощью GridSearchCV\n",
    "#, для балансировки целевого признака применим class_weight='balanced'\n",
    "LR_params = {'C': range(9, 15), 'solver': ['sag', 'liblinear']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:   30.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 9, 'solver': 'sag'} 0.8091259925401583\n",
      "Wall time: 32.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_LR = LogisticRegression(random_state=287, class_weight='balanced')\n",
    "LR_class_weight = GridSearchCV(model_LR, LR_params, cv=3, n_jobs=-1, scoring='f1', verbose=True)\n",
    "# Обучим модель\n",
    "LR_class_weight.fit(features_tr, target_train)\n",
    "print(LR_class_weight.best_params_, LR_class_weight.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скоринг модели Логистической регрессии F1: 0.83\n"
     ]
    }
   ],
   "source": [
    "#Модель логистической регрессии, для балансировки целевого признака применим class_weight='balanced'\n",
    "model_logistic = LogisticRegression(random_state=287, class_weight='balanced', solver='liblinear', C=9)\n",
    "model_logistic.fit(features_tr, target_train) # обучим модель на тренировочной выборке\n",
    "predict_m = model_logistic.predict(features_tt)\n",
    "print('Скоринг модели Логистической регрессии F1:',round(f1_score(target_test, predict_m), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Найдем лучшие гиперпараметры LGBMClassifier с помощью GridSearchCV\n",
    "LGBM_params = {'max_depth': range(2,4),'num_leaves': range(2,4),\n",
    "               'n_estimators': range(400, 700, 100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 2, 'n_estimators': 600, 'num_leaves': 3} 0.7940684386978575\n",
      "Wall time: 3min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Найдем оптимальные гиперпараметры, для балансировки целевого признака применим class_weight='balanced'\n",
    "model_LGBM = LGBMClassifier(random_state=287, class_weight='balanced')\n",
    "\n",
    "LGBM_class_weight = GridSearchCV(model_LGBM, LGBM_params, cv=3, n_jobs=-1, \n",
    "                                 scoring='f1', verbose=True)\n",
    "# Обучим модель\n",
    "LGBM_class_weight.fit(features_tr, target_train)\n",
    "print(LGBM_class_weight.best_params_, LGBM_class_weight.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скоринг модели LGBMClassifier F1: 0.8\n"
     ]
    }
   ],
   "source": [
    "#Модель LGBM, для балансировки целевого признака применим class_weight='balanced'\n",
    "model_LGBM = LGBMClassifier(random_state=287, \n",
    "                            class_weight='balanced', \n",
    "                            num_leaves=3,\n",
    "                            max_depth=2, n_estimators=600)\n",
    "model_LGBM.fit(features_tr, target_train) # обучим модель на тренировочной выборке\n",
    "predict_m = model_LGBM.predict(features_tt)\n",
    "print('Скоринг модели LGBMClassifier F1:',round(f1_score(target_test, predict_m), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы<a id='3-bullet'></a>\n",
    "1. Для поиска лучших гиперпараметров для наших моделей LogisticRegression и LGBMClassifier мы применили GridSearchCV;\n",
    "2. В виду того что целевой признак имеет сильный дисбаланс в отрицательную сторону при обучении моделей мы применили class_weight='balanced';\n",
    "3. Лучшей из двух моделей по итогам испытания оказалась Логистическая регрессия с значением скоринга F1 = 0.83, что достаточно по условиям поставленной задачи."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
