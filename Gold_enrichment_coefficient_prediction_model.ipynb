{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание проекта\n",
    "\n",
    "* Необходимо подготовить прототип модели машинного обучения для «Цифры» - компании которая разрабатывает решения для эффективной работы промышленных предприятий.\n",
    "* Модель должна предсказать коэффициент восстановления золота из золотосодержащей руды. В вашем распоряжении данные с параметрами добычи и очистки.\n",
    "* Технология обогащения золота делится на 3 технологических процесса: флотация, первый этап очистки, второй этап очистки. На каждом из них концентрация золота растет, а примсей падает.\n",
    "* Модель поможет оптимизировать производство, чтобы не запускать предприятие с убыточными характеристиками."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание данных\n",
    "\n",
    "### Признаки на входе в технологический процесс флотации\n",
    "* rougher.input.feed_ag — концентрация серебра\n",
    "* rougher.input.feed_pb — концентрация свинца\n",
    "* rougher.input.feed_rate — скорость подачи\n",
    "* rougher.input.feed_size — размер пульпы\n",
    "* rougher.input.feed_sol — концентрация примесей\n",
    "* rougher.input.feed_au — концентрация золота\n",
    "* rougher.input.floatbank10_sulfate — реагент\n",
    "* rougher.input.floatbank10_xanthate — реагент\n",
    "* rougher.input.floatbank11_sulfate — реагент\n",
    "* rougher.input.floatbank11_xanthate — реагент\n",
    "\n",
    "### Целевые признаки\n",
    "* rougher.output.recovery — эффективность обогащения чернового концентрата\n",
    "* final.output.recovery — эффективность обогащения финального концентрата"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Часть 1. Подготовка данных](#1-bullet)\n",
    "\n",
    "## [Чачть 2. Анализ данных](#2-bullet)\n",
    "\n",
    "## [Чачть 3. Модель](#3-bullet) \n",
    "\n",
    "## [Вывод ](#4-bullet) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка данных <a id='1-bullet'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', None) \n",
    "import datetime\n",
    "from scipy import stats as st\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция проверки общего количества пропусков в % выражении\n",
    "def number_of_passes(data):\n",
    "    passes = pd.DataFrame(data.isnull().sum())\n",
    "    passes['index'] = passes.index\n",
    "    passes = passes.reset_index(drop =True)\n",
    "    passes.columns = ['sum_NaN', 'specifications']\n",
    "    passes = passes[['specifications', 'sum_NaN']]\n",
    "    passes = passes.query('sum_NaN != 0').sort_values('specifications', ascending=False).reset_index(drop =True)\n",
    "    passes['passes_NaN'] = round(passes['sum_NaN'] / data.shape[0] * 100, 1)\n",
    "    return passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ознакомимся с данными и количеством пропусков в них\n",
    "df_train = pd.read_csv('C:/Users/vyugo/Documents/!Python/2. Проекты Я.Практикум/8. Модель по предсказанию коэффициента востановления золота из руды/gold_recovery_train.csv')\n",
    "df_test = pd.read_csv('C:/Users/vyugo/Documents/!Python/2. Проекты Я.Практикум/8. Модель по предсказанию коэффициента востановления золота из руды/gold_recovery_test.csv')\n",
    "df_full = pd.read_csv('C:/Users/vyugo/Documents/!Python/2. Проекты Я.Практикум/8. Модель по предсказанию коэффициента востановления золота из руды/gold_recovery_full.csv')\n",
    "\n",
    "df_train_nan = number_of_passes(df_train)\n",
    "df_test_nan = number_of_passes(df_test)\n",
    "df_full_nan = number_of_passes(df_full)\n",
    "\n",
    "#display(df_train_nan.head(50))\n",
    "#display(df_test_nan.head())\n",
    "#display(df_full_nan.head())\n",
    "\n",
    "#df_test.head()\n",
    "#df_train.head()\n",
    "#df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверем, что эффективность обогащения рассчитана правильно найдем MAE на обучающей выборке\n",
    "def recovery(df):\n",
    "    C = df['rougher.output.concentrate_au']\n",
    "    F = df['rougher.input.feed_au']\n",
    "    T = df['rougher.output.tail_au']\n",
    "    df['recovery.check'] = (C * (F - T)) / (F * (C - T)) * 100\n",
    "    mae = sum(abs(df['rougher.output.recovery'] - df['recovery.check']).fillna(0)) / len(df)\n",
    "    print('MAE:',mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 7.883623897364653e-15\n"
     ]
    }
   ],
   "source": [
    "# Проверим правильно ли рассчитано МАЕ в тестовой выборке\n",
    "recovery(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-4b65dcee1822>:2: FutureWarning: Index.__xor__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__xor__.  Use index.symmetric_difference(other) instead\n",
      "  features = (pd.DataFrame(set(df_train.columns ^ df_test.columns))\n"
     ]
    }
   ],
   "source": [
    "# Найдем и проанализируем отсутствующие в тестовой выборке признаки\n",
    "features = (pd.DataFrame(set(df_train.columns ^ df_test.columns))\n",
    "                   .sort_values(by=0).reset_index(drop=True))\n",
    "#display(features)\n",
    "# Удалим из полученного списка целевые признаки ('rougher.output.recovery', 'final.output.recovery'), \n",
    "# для последующей фильтрации обучающих выборок\n",
    "features_list = list(features.drop([4, 26])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем NaN в тренировочной выборке\n",
    "df_train = df_train.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем date в индекс\n",
    "df_train = df_train.set_index('date')\n",
    "df_test = df_test.set_index('date')\n",
    "df_full = df_full.set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "1. Исходная обучающая выборка состоит из 87 столбцов и 16860 строк.\n",
    "2. Все столбцы имеют тип float, кроме столбца date - значения которого мы преобразуем в формат даты.\n",
    "3. В виду того что данные содержат много пропусков, для расчета МАЕ (среднее абсолютное отклонение) мы удалили строки с пропусками. Полученное МАЕ стремиться к 0, что говорит о точности расчета эффективности обогащения.\n",
    "4. Мы сравнили обучающую и тестовую выборки, было обнаружено 33 признака отсутствующих в тестовой выборке - по условиям задачи это целевые признаки трех циклов обогащения металлов + те что расчитываются позднее (calculetion).\n",
    "5. Признаки содержащие output - это результаты каждлго из технологических циклов обогащения.\n",
    "6. Наш целевой признак для создания модели rougher.output.recovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Анализ данных <a id='2-bullet'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция по построению графиков\n",
    "def f_boxplot_hist(df, column1, column2, column3, column4, name_histogram, name_box):\n",
    "    #Построим диаграммы размаха\n",
    "    fig1 = go.Figure()\n",
    "    fig1.add_trace(go.Box(y=df[column1], name=column1))\n",
    "    fig1.add_trace(go.Box(y=df[column2], name=column2))\n",
    "    fig1.add_trace(go.Box(y=df[column3], name=column3))\n",
    "    fig1.add_trace(go.Box(y=df[column4], name=column4))\n",
    "    fig1.update_layout(\n",
    "    title=name_box,\n",
    "    title_x = 0.5,\n",
    "    legend=dict(x=.1, xanchor=\"center\", orientation=\"h\"),\n",
    "    barmode='overlay',\n",
    "    margin=dict(l=0, r=0, t=30, b=0))\n",
    "    fig1.show()\n",
    "    # Построим гистораммы\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Histogram(x=df[column1], opacity=0.75, name=column1, histnorm='probability density'))\n",
    "    fig.add_trace(go.Histogram(x=df[column2], opacity=0.75, name=column2, histnorm='probability density'))\n",
    "    fig.add_trace(go.Histogram(x=df[column3], opacity=0.75, name=column3, histnorm='probability density'))\n",
    "    fig.add_trace(go.Histogram(x=df[column4], opacity=0.75, name=column4, histnorm='probability density'))\n",
    "    fig.update_layout(\n",
    "    title=name_histogram,\n",
    "    title_x = 0.5,\n",
    "    xaxis_title=\"Концентрация\",\n",
    "    yaxis_title=\"Плотность\",\n",
    "    legend=dict(x=.1, xanchor=\"center\", orientation=\"h\"),\n",
    "    barmode='overlay',\n",
    "    margin=dict(l=0, r=0, t=30, b=0))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Построим графики концентраций Au на различных этапах очистки\n",
    "# f_boxplot_hist(df_full,'rougher.input.feed_au', \n",
    "#                'rougher.output.concentrate_au', \n",
    "#                'primary_cleaner.output.concentrate_au',\n",
    "#                'final.output.concentrate_au',\n",
    "#                'Гистограмма концентраций Au', 'Диаграмма размаха концентрации Au')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "1. На вышеприведенных графиках концентрации Au мы видим нормальное распределение концентрации на 3-х этапах обработки включая концентрацию в первоначальном сырье, что подтверждает адекватность наших данных. \n",
    "2. Каждый из этапов обработки золота демонстрирует рост концентрации, причем там где заканчиваются максимумы предидущего этапа начинаются минимумы следующего.\n",
    "3. На гистограмме, если рассмотреть график каждого из этапов обработки отдельно (позволяет Plotly), хорошо заметны пики у 0 концентрации. Также выбросы продолжаются до первого квантиля каждого из этапов. Это нормальная ситуация в промышленности т.к. любой процесс химической/физической обработки имеет переходный характер т.е. на каждом этапе обработки определенного количества пульпы оборудование находиться в загруженной и незагруженной фазе - причем датчики непрерывно выдают показания. Когда физически в установке в начале каждого процесса обработки отсутствует пульпа - датчики будут выдавать 0 концентрации.\n",
    "4. Отфильтруем данные по нижнему квантилю каждого из этапов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Построим графики концентраций Pb на различных этапах очистки\n",
    "# f_boxplot_hist(df_full,'rougher.input.feed_pb', \n",
    "#                'rougher.output.concentrate_pb', \n",
    "#                'primary_cleaner.output.concentrate_pb',\n",
    "#                'final.output.concentrate_pb',\n",
    "#                'Гистограмма концентраций Pb', 'Диаграмма размаха концентрации Pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "1. На вышеприведенных графиках концентрации Pb мы видим нормальное распределение концентрации на 3-х этапах обработки включая концентрацию в первоначальном сырье, что подтверждает адекватность наших данных. \n",
    "2. Т.к. нашей задачей в этом технологическом процессе является повышение концентрации золота и понижение концентрации остальных веществ - это мы и видим на наших графиках. \n",
    "3. На каждом последующем этапе обработки среднее концентрации свинца падает вплоть до первого эиапа обработки и останавливается на 10 единицах. \n",
    "4. Далее подобным физикохимическим процессом понизить содержание свинца в концентрате золота невозможно - нужно искать другие методы.\n",
    "5. По аналогичным причинам(как у золота) мы видим максимумы концентрации у 0 каждого из этапов обработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Построим графики концентраций Ag на различных этапах очистки\n",
    "# f_boxplot_hist(df_full,'rougher.input.feed_ag', \n",
    "#                'rougher.output.concentrate_ag', \n",
    "#                'primary_cleaner.output.concentrate_ag',\n",
    "#                'final.output.concentrate_ag',\n",
    "#                'Гистограмма концентраций Ag', 'Диаграмма размаха концентрации Ag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "1. На вышеприведенных графиках концентрации Ag мы видим нормальное распределение концентрации на 3-х этапах обработки включая концентрацию в первоначальном сырье, что подтверждает адекватность наших данных. \n",
    "2. Т.к. нашей задачей в этом технологическом процессе является повышение концентрации золота и понижение концентрации остальных веществ - это мы и видим на наших графиках. Финальная средняя концентрация  Ag падает до 5 единиц.\n",
    "3. По аналогичным причинам(как у золота и свинца) мы видим максимумы концентрации у 0 каждого из этапов обработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Построим графики концентраций Sol на различных этапах очистки\n",
    "# f_boxplot_hist(df_full,'rougher.input.feed_sol', \n",
    "#                'rougher.output.concentrate_sol', \n",
    "#                'primary_cleaner.output.concentrate_sol',\n",
    "#                'final.output.concentrate_sol',\n",
    "#                'Гистограмма концентраций Sol', 'Диаграмма размаха концентрации Sol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим функцию для построения диаграммы размаха размера гранул сырья на тренировочной, тестовой и общей выборках\n",
    "def box(sign1, sign2, sign3, title, xaxis_title, yaxis_title):\n",
    "    fig1 = go.Figure()\n",
    "    fig1.add_trace(go.Box(y=sign1, name='Train'))\n",
    "    fig1.add_trace(go.Box(y=sign2, name='Test'))\n",
    "    fig1.add_trace(go.Box(y=sign3, name='Full'))\n",
    "    fig1.update_layout(\n",
    "    title=title,\n",
    "    title_x = 0.5,\n",
    "    xaxis_title=xaxis_title,\n",
    "    yaxis_title=yaxis_title,\n",
    "    #legend=dict(x=.2, xanchor=\"center\", orientation=\"h\"),\n",
    "    barmode='overlay',\n",
    "    margin=dict(l=0, r=0, t=30, b=0))\n",
    "    fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим распределение гранул сырья на всех наших выборках\n",
    "# box(df_train['rougher.input.feed_size'], \n",
    "#     df_test['rougher.input.feed_size'],\n",
    "#     df_full['rougher.input.feed_size'],\n",
    "#     'График распределения', 'Распределение размера гранул сырья', 'Размер')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "1. Распределение размера гранул сырья между тренировочной и тестовой выборками отличаются незначительно.\n",
    "2. Распределение размера гранул сырья между полной выборкой и тренировочной почти отсутствуют."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция подсчета суммарной концентрации на разных стадиях обработки\n",
    "def total_concentration(processing_step): \n",
    "    drop_rate_size = df_full.drop(['rougher.input.feed_rate', 'rougher.input.feed_size'], axis=1)\n",
    "    processing_step = list(filter(lambda x: x.startswith(processing_step), drop_rate_size.columns))\n",
    "    return df_full[processing_step].sum(axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Суммарная концентрация подаваемого сырья\n",
    "df_rougher_input = total_concentration('rougher.input.feed')\n",
    "# Суммарная концентрация после этапа флотации\n",
    "df_rougher_output = total_concentration('rougher.output.concentrate')\n",
    "# Суммарная концентрация после первого этапа\n",
    "df_primary_cleaner = total_concentration('primary_cleaner.output.concentrate')\n",
    "# Суммарная концентрация после второго этапа\n",
    "df_final_output = total_concentration('final.output.concentrate')\n",
    "\n",
    "# Построим гисторамму всех этапов, Каждый этап можно рассмотреть отдельно переключаясь в Plotly\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Histogram(x=df_rougher_input, opacity=0.75, name='Подаваемого сырья', histnorm='probability density'))\n",
    "# fig.add_trace(go.Histogram(x=df_rougher_output, opacity=0.75, name='После этапа флотации', histnorm='probability density'))\n",
    "# fig.add_trace(go.Histogram(x=df_primary_cleaner, opacity=0.75, name='После первого этапа', histnorm='probability density'))\n",
    "# fig.add_trace(go.Histogram(x=df_final_output, opacity=0.75, name='После второго этапа', histnorm='probability density'))\n",
    "# fig.update_layout(\n",
    "# title=\"Концентрация всех веществ на разных этапах\",\n",
    "# title_x = 0.5,\n",
    "# xaxis_title=\"Концентрация\",\n",
    "# yaxis_title=\"Плотность\",\n",
    "# legend=dict(x=.1, xanchor=\"center\", orientation=\"h\"),\n",
    "# barmode='overlay',\n",
    "# margin=dict(l=0, r=0, t=30, b=0))\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "1. На гистограмме концентраций всех веществ на разных этапах мы видим нормальное распределение, что подтверждает адекватность наших данных. \n",
    "2. На гистограмме каждого из этапов обработки отдельно (позволяет Plotly), хорошо заметны пики у 0 концентрации. Это нормальная ситуация в промышленности т.к. любой процесс химической/физической обработки имеет переходный характер т.е. на каждом этапе обработки определенного количества пульпы оборудование находиться в загруженной и незагруженной фазе - причем датчики непрерывно выдают показания. Когда физически в установке в начале каждого процесса обработки отсутствует пульпа - датчики будут выдавать 0 концентрации.\n",
    "4. Удалять выбросы имеет смысл только на обучающей выборке - чтобы наша модель в последствии не воспринимала их как достоверные значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14608, 87)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Удалим аномалии и выбросы из данных\n",
    "df_train = df_train.loc[(1.711728 <= df_train['rougher.input.feed_au']) & (df_train['rougher.input.feed_au'] <= 14.09336) &\n",
    "            (0.3485492 <= df_train['rougher.input.feed_pb']) & (df_train['rougher.input.feed_pb'] <= 6.52037) &\n",
    "            (2.173518 <= df_train['rougher.input.feed_ag']) & (df_train['rougher.input.feed_ag'] <= 14.86965) &\n",
    "            (21.80363 <= df_train['rougher.input.feed_sol']) & (df_train['rougher.input.feed_sol'] <= 50.20884)]\n",
    "# Размер таблицы после удаления выбросов\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отфильтруем из выборок признаки которые не будут использоваться в обучении модели \n",
    "df_train = df_train.drop(features_list, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rougher.input.feed_sol</th>\n",
       "      <th>rougher.input.feed_pb</th>\n",
       "      <th>rougher.input.feed_ag</th>\n",
       "      <th>rougher.input.feed_au</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14608.000000</td>\n",
       "      <td>14608.000000</td>\n",
       "      <td>14608.000000</td>\n",
       "      <td>14608.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.485137</td>\n",
       "      <td>3.565754</td>\n",
       "      <td>8.698680</td>\n",
       "      <td>8.001774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.340154</td>\n",
       "      <td>1.081851</td>\n",
       "      <td>1.925019</td>\n",
       "      <td>1.906028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.803630</td>\n",
       "      <td>0.365561</td>\n",
       "      <td>2.598802</td>\n",
       "      <td>1.744413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>34.052179</td>\n",
       "      <td>2.802313</td>\n",
       "      <td>7.171959</td>\n",
       "      <td>6.669969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36.988676</td>\n",
       "      <td>3.457345</td>\n",
       "      <td>8.243960</td>\n",
       "      <td>7.742544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>39.443914</td>\n",
       "      <td>4.286295</td>\n",
       "      <td>10.043812</td>\n",
       "      <td>9.229325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>48.363177</td>\n",
       "      <td>6.520370</td>\n",
       "      <td>14.766530</td>\n",
       "      <td>13.923250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rougher.input.feed_sol  rougher.input.feed_pb  rougher.input.feed_ag  \\\n",
       "count            14608.000000           14608.000000           14608.000000   \n",
       "mean                36.485137               3.565754               8.698680   \n",
       "std                  4.340154               1.081851               1.925019   \n",
       "min                 21.803630               0.365561               2.598802   \n",
       "25%                 34.052179               2.802313               7.171959   \n",
       "50%                 36.988676               3.457345               8.243960   \n",
       "75%                 39.443914               4.286295              10.043812   \n",
       "max                 48.363177               6.520370              14.766530   \n",
       "\n",
       "       rougher.input.feed_au  \n",
       "count           14608.000000  \n",
       "mean                8.001774  \n",
       "std                 1.906028  \n",
       "min                 1.744413  \n",
       "25%                 6.669969  \n",
       "50%                 7.742544  \n",
       "75%                 9.229325  \n",
       "max                13.923250  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверим результаты фильтрации\n",
    "df_train[{'rougher.input.feed_au', 'rougher.input.feed_pb', \n",
    "                  'rougher.input.feed_ag', 'rougher.input.feed_sol'}].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим выборку на признаки и целевые признаки\n",
    "target_train_rougher = df_train['rougher.output.recovery'] \n",
    "target_train_final = df_train['final.output.recovery']\n",
    "features_train = df_train.drop(['rougher.output.recovery', 'final.output.recovery'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовим тестовые признаки\n",
    "features_test = df_test.dropna()\n",
    "target_test_rougher = df_full['rougher.output.recovery'][features_test.index].fillna(method='ffill')\n",
    "target_test_final = df_full['final.output.recovery'][features_test.index].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Функция по удалению коррелированных признаков\n",
    "def filter_df_corr(inp_data, corr_val):\n",
    "       # Cоздадим матрицу корреляций\n",
    "    if isinstance(inp_data, np.ndarray):\n",
    "        inp_data = pd.DataFrame(data=inp_data)\n",
    "        array_flag = True\n",
    "    else:\n",
    "        array_flag = False\n",
    "    corr_matrix = inp_data.corr()\n",
    "\n",
    "    # Найдем коррелированные столбцы\n",
    "    drop_cols = []\n",
    "    n_cols = len(corr_matrix.columns)\n",
    "\n",
    "    for i in range(n_cols):\n",
    "        for k in range(i+1, n_cols):\n",
    "            val = corr_matrix.iloc[k, i]\n",
    "            col = corr_matrix.columns[i]\n",
    "            row = corr_matrix.index[k]\n",
    "            if abs(val) >= corr_val:\n",
    "                # Напечатаем коррелированные столбцы\n",
    "                #print(col, \"|\", row, \"|\", round(val, 2))\n",
    "                drop_cols.append(col)\n",
    "\n",
    "    # Удалим коррелированные столбцы\n",
    "    drop_cols = set(drop_cols)\n",
    "    inp_data = inp_data.drop(columns=drop_cols)\n",
    "    \n",
    "    if array_flag:\n",
    "        return inp_data.values\n",
    "    else:\n",
    "        return inp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим коррелированные признаки на тренировочной выборке\n",
    "features_train = filter_df_corr(features_train, 0.85)\n",
    "\n",
    "# Удалим коррелированные признаки на тестовой выборке\n",
    "features_test = filter_df_corr(features_test, 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Произведем масштабирование признаков тренировочной выборки\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train)\n",
    "features_train = scaler.transform(features_train)\n",
    "\n",
    "# Произведем масштабирование признаков тренировочной выборки\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_test)\n",
    "features_test = scaler.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Модель <a id='3-bullet'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Напишм функцию для вычисления sMAPE  «симметричное среднее абсолютное процентное отклонение», \n",
    "# Yi - целевой признак, Yii - предсказание \n",
    "def sMAPE(Yi, Yii): \n",
    "    return ((abs(Yi - Yii) / ((abs(Yi) + abs(Yii)) / 2)).mean()) * 100\n",
    "# Создадим функцию оценки для GreedSearchCV\n",
    "sMAPE_score_greed = make_scorer(sMAPE, greater_is_better = False)\n",
    "\n",
    "# Создадим функцию оценки для модели\n",
    "sMAPE_score = make_scorer(sMAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запишем параметры модели\n",
    "tree_params = {\n",
    "    'max_depth': range(2,15),\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'min_samples_leaf': range(2,5),\n",
    "    'min_samples_split': range(2,5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vyugo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass groups=date\n",
      "2016-01-15 00:00:00    70.541216\n",
      "2016-01-15 01:00:00    69.266198\n",
      "2016-01-15 02:00:00    68.116445\n",
      "2016-01-15 03:00:00    68.347543\n",
      "2016-01-15 04:00:00    66.927016\n",
      "                         ...    \n",
      "2018-08-18 06:59:59    73.755150\n",
      "2018-08-18 07:59:59    69.049291\n",
      "2018-08-18 08:59:59    67.002189\n",
      "2018-08-18 09:59:59    65.523246\n",
      "2018-08-18 10:59:59    70.281454\n",
      "Name: final.output.recovery, Length: 14608, dtype: float64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 351 candidates, totalling 1755 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1755 out of 1755 | elapsed:   37.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2} -11.432620558075374\n"
     ]
    }
   ],
   "source": [
    "# Найдем оптимальные гиперпараметры\n",
    "tree = DecisionTreeRegressor(random_state=12345)\n",
    "tree_grid = GridSearchCV(tree, tree_params, cv=5, n_jobs=-1, scoring=sMAPE_score_greed, verbose=True)\n",
    "# Обучим модель\n",
    "tree_grid.fit(features_train, target_train_rougher, target_train_final)\n",
    "# печать оптимальных параметров\n",
    "print(tree_grid.best_params_, tree_grid.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Мы получили следующие гиперпараметры {'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2} \n",
    "def tree(Ai, Bi, Ci, cv):\n",
    "    tree = DecisionTreeRegressor(random_state=12345, max_depth=4, \n",
    "                                     max_features='sqrt', min_samples_leaf=2, min_samples_split=2)\n",
    "    rougher_sMAPE = cross_val_score(tree, Ai, Bi, cv=cv, scoring=sMAPE_score)\n",
    "    final_sMAPE = cross_val_score(tree, Ai, Ci, cv=cv, scoring=sMAPE_score) \n",
    "    return print('Итоговая sMAPE дерева решений:', round((0.25 * rougher_sMAPE + 0.75 * final_sMAPE).mean(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоговая sMAPE дерева решений: 11.15\n"
     ]
    }
   ],
   "source": [
    "# Найдем sMAPE на тренировочной выборке\n",
    "tree(features_train, target_train_rougher, target_train_final, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоговая sMAPE дерева решений: 9.99\n"
     ]
    }
   ],
   "source": [
    "# Найдем sMAPE на тестовой выборке\n",
    "tree(features_test, target_test_rougher, target_test_final, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_params = {\n",
    "    'min_samples_split': range(2,4),\n",
    "    'min_samples_leaf': range(2,5),\n",
    "    'n_estimators': range(2, 20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vyugo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass groups=date\n",
      "2016-01-15 00:00:00    70.541216\n",
      "2016-01-15 01:00:00    69.266198\n",
      "2016-01-15 02:00:00    68.116445\n",
      "2016-01-15 03:00:00    68.347543\n",
      "2016-01-15 04:00:00    66.927016\n",
      "                         ...    \n",
      "2018-08-18 06:59:59    73.755150\n",
      "2018-08-18 07:59:59    69.049291\n",
      "2018-08-18 08:59:59    67.002189\n",
      "2018-08-18 09:59:59    65.523246\n",
      "2018-08-18 10:59:59    70.281454\n",
      "Name: final.output.recovery, Length: 14608, dtype: float64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 14} -13.482878176617323\n"
     ]
    }
   ],
   "source": [
    "# Найдем оптимальные гиперпараметры\n",
    "forest = RandomForestRegressor(random_state=12345)\n",
    "forest_class_weight = GridSearchCV(forest, forest_params, cv=5, n_jobs=-1, scoring=sMAPE_score_greed, verbose=True)\n",
    "# Обучим модель\n",
    "forest_class_weight.fit(features_train, target_train_rougher, target_train_final)\n",
    "print(forest_class_weight.best_params_, forest_class_weight.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Мы получили следующие гиперпараметры {'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 14}\n",
    "\n",
    "# Напишем функцию по расчету sMAPE для модели случайного леса\n",
    "# Ai - признаки; Bi - целевой признак rougher, Ci - целевой признак rougher final \n",
    "def forest(Ai, Bi, Ci, cv):\n",
    "    model_forest = RandomForestRegressor(n_estimators = 14, min_samples_leaf=4, min_samples_split=2, random_state=12345)\n",
    "    rougher_sMAPE = cross_val_score(model_forest, Ai, Bi, cv=cv, scoring=sMAPE_score)\n",
    "    final_sMAPE = cross_val_score(model_forest, Ai, Ci, cv=cv, scoring=sMAPE_score) \n",
    "    return print('Итоговая sMAPE случайного леса:', round((0.25 * rougher_sMAPE + 0.75 * final_sMAPE).mean(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоговая sMAPE случайного леса: 10.98\n"
     ]
    }
   ],
   "source": [
    "# Найдем итоговую sMAPE на тренировочной выборке для случайного леса\n",
    "forest(features_train, target_train_rougher, target_train_final, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоговая sMAPE случайного леса: 9.76\n"
     ]
    }
   ],
   "source": [
    "# Найдем итоговую sMAPE на тестовой выборке для случайного леса\n",
    "forest(features_test, target_test_rougher, target_test_final, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритм k-ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    'n_neighbors': range(2,8),\n",
    "    'weights': ['uniform'],\n",
    "    'metric': ['minkowski']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vyugo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass groups=date\n",
      "2016-01-15 00:00:00    70.541216\n",
      "2016-01-15 01:00:00    69.266198\n",
      "2016-01-15 02:00:00    68.116445\n",
      "2016-01-15 03:00:00    68.347543\n",
      "2016-01-15 04:00:00    66.927016\n",
      "                         ...    \n",
      "2018-08-18 06:59:59    73.755150\n",
      "2018-08-18 07:59:59    69.049291\n",
      "2018-08-18 08:59:59    67.002189\n",
      "2018-08-18 09:59:59    65.523246\n",
      "2018-08-18 10:59:59    70.281454\n",
      "Name: final.output.recovery, Length: 14608, dtype: float64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   30.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'minkowski', 'n_neighbors': 2, 'weights': 'uniform'} KNeighborsRegressor(n_neighbors=2) 13.738379847868753\n"
     ]
    }
   ],
   "source": [
    "# Найдем оптимальные гиперпараметры\n",
    "grid_knn = GridSearchCV(KNeighborsRegressor(), grid_params, cv=5, n_jobs=-1, scoring=sMAPE_score, verbose=1)\n",
    "grid_knn.fit(features_train, target_train_rougher, target_train_final)\n",
    "print(grid_knn.best_params_, grid_knn.best_estimator_, grid_knn.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Мы получили следующие гиперпараметры {'metric': 'minkowski', 'n_neighbors': 2, 'weights': 'uniform'}\n",
    "\n",
    "# Напишем функцию по расчету sMAPE для модели KNN\n",
    "# Ai - признаки; Bi - целевой признак rougher, Ci - целевой признак rougher final \n",
    "def KNN(Ai, Bi, Ci, cv):\n",
    "    KNN_model = KNeighborsRegressor(n_neighbors = 2, weights='uniform', metric='minkowski')\n",
    "    rougher_sMAPE = cross_val_score(KNN_model, Ai, Bi, cv=cv, scoring=sMAPE_score)\n",
    "    final_sMAPE = cross_val_score(KNN_model, Ai, Ci, cv=cv, scoring=sMAPE_score) \n",
    "    return print('Итоговая sMAPE KNN:', round((0.25 * rougher_sMAPE + 0.75 * final_sMAPE).mean(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоговая sMAPE KNN: 12.74\n"
     ]
    }
   ],
   "source": [
    "# Найдем итоговую sMAPE на тренировочной выборке для KNN\n",
    "KNN(features_train, target_train_rougher, target_train_final, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоговая sMAPE KNN: 10.67\n"
     ]
    }
   ],
   "source": [
    "# Найдем итоговую sMAPE на тестовой выборке для KNN\n",
    "KNN(features_test, target_test_rougher, target_test_final, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Вывод<a id='4-bullet'></a>\n",
    "* Дерево решений и Случайный лес дают почти одинаково хороший результат для предсказания итоговой концентрации золота на выходе технологического процесса, но алгоритм дерева решений выигрывает по скорости - рекомендуем его!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
